# -*- coding: utf-8 -*-
from dotenv import load_dotenv
import os
import sys
from langchain_ollama import OllamaLLM
from langchain_ollama import OllamaEmbeddings
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate, PromptTemplate # PromptTemplate ì¶”ê°€
from langchain.chains import create_retrieval_chain, LLMChain # LLMChain ì¶”ê°€
from langchain.chains.combine_documents import create_stuff_documents_chain

# --- Contextual Compressionì„ ìœ„í•œ ì¶”ê°€ ì„í¬íŠ¸ ---
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import LLMChainExtractor
# ----------------------------------------------------

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œ
load_dotenv()

# --- í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ---
OLLAMA_HOST = os.environ.get('OLLAMA_HOST', 'http://127.0.0.1:11434')
OLLAMA_LLM_MODEL = os.environ.get('OLLAMA_LLM_MODEL', 'llama3')
OLLAMA_EMBEDDING_MODEL = os.environ.get('OLLAMA_EMBEDDING_MODEL', 'nomic-embed-text')
CHROMA_DB_PATH = os.environ.get('CHROMA_DB_PATH', './chroma_db')

print(f"Ollama Host: {OLLAMA_HOST}")
print(f"LLM Model: {OLLAMA_LLM_MODEL}")
print(f"Embedding Model: {OLLAMA_EMBEDDING_MODEL}")
print(f"Chroma DB Path: {CHROMA_DB_PATH}")

def main():
    print("\n--- RAG ê¸°ë°˜ ì§ˆì˜ ì‘ë‹µ ì‹œìŠ¤í…œ ì‹œì‘ ---")

    # --- 1. LLM ë° ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ---
    try:
        llm = OllamaLLM(model=OLLAMA_LLM_MODEL, base_url=OLLAMA_HOST, temperature=0.1)
        embeddings = OllamaEmbeddings(model=OLLAMA_EMBEDDING_MODEL, base_url=OLLAMA_HOST)
        print(f"âœ… Ollama LLM ('{OLLAMA_LLM_MODEL}') ë° Embedding Model ('{OLLAMA_EMBEDDING_MODEL}') ë¡œë“œ ì™„ë£Œ.")
    except Exception as e:
        print(f"âŒ Ollama LLM ë˜ëŠ” Embedding Model ë¡œë“œ ì‹¤íŒ¨: {e}")
        print("ğŸ’¡ Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€, ì§€ì •ëœ ëª¨ë¸ë“¤ì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        print(f"   ì˜ˆ: ollama serve ì‹¤í–‰ í›„, ollama pull {OLLAMA_LLM_MODEL} ë° ollama pull {OLLAMA_EMBEDDING_MODEL}")
        sys.exit(1)

    # --- 2. Chroma VectorStore ë¡œë“œ ---
    if not os.path.exists(CHROMA_DB_PATH):
        print(f"âŒ Chroma DB ê²½ë¡œ '{CHROMA_DB_PATH}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ 'python ingest.py'ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
        sys.exit(1)

    try:
        vectorstore = Chroma(persist_directory=CHROMA_DB_PATH, embedding_function=embeddings)
        
        # --- ê¸°ë³¸ ë¦¬íŠ¸ë¦¬ë²„ ì„¤ì • (ë” ë§ì€ ë¬¸ì„œë¥¼ ê°€ì ¸ì™€ ì••ì¶•ê¸°ì— ì „ë‹¬) ---
        base_retriever = vectorstore.as_retriever(search_kwargs={"k": 20}) # ì¼ë‹¨ 20ê°œ ê°€ì ¸ì˜¤ê¸°
        
        # --- ContextualCompressionRetriever ì„¤ì • (Custom Prompt ì ìš©) ---
        # 1. ì••ì¶•ê¸°(Extractor)ê°€ ì‚¬ìš©í•  LLM í”„ë¡¬í”„íŠ¸ ì •ì˜
        _compress_template = """ë‹¤ìŒ ë¬¸ì„œì™€ ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ, ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë° ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ë¶€ë¶„ë§Œ ë¬¸ì„œì—ì„œ ì¶”ì¶œí•˜ì„¸ìš”.
        ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì •ë³´ë¥¼ í¬í•¨í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´, "NO_OUTPUT"ì´ë¼ê³  ì‘ë‹µí•˜ì„¸ìš”.
        ì§ˆë¬¸ì— ì§ì ‘ ë‹µí•˜ì§€ ë§ˆì„¸ìš”. ì˜¤ì§ ë¬¸ì„œì—ì„œ ê´€ë ¨ëœ ìŠ¤ë‹ˆí«(ì§§ì€ êµ¬ì ˆ)ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.
        
        ë¬¸ì„œ:
        {context}
        
        ì§ˆë¬¸: {question}
        
        ê´€ë ¨ ìŠ¤ë‹ˆí«:"""
        COMPRESSOR_PROMPT = PromptTemplate(template=_compress_template, input_variables=["context", "question"])

        # 2. ì••ì¶•ê¸° LLMì„ ìœ„í•œ LLMChain ìƒì„± (ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)
        compressor_llm_chain = LLMChain(llm=llm, prompt=COMPRESSOR_PROMPT)

        # 3. LLMChainExtractorì— ì»¤ìŠ¤í…€ LLMChain ì—°ê²°
        compressor = LLMChainExtractor(llm_chain=compressor_llm_chain) # ì»¤ìŠ¤í…€ LLMChain ì—°ê²°

        # 4. ContextualCompressionRetriever ìƒì„±
        compression_retriever = ContextualCompressionRetriever(
            base_compressor=compressor, 
            base_retriever=base_retriever
        )
        
        print(f"âœ… Chroma VectorStore '{CHROMA_DB_PATH}' ë¡œë“œ ë° ContextualCompressionRetriever (k=20, Custom Compressor Prompt) ì„¤ì • ì™„ë£Œ.")
    except Exception as e:
        print(f"âŒ Chroma VectorStore ë¡œë“œ ì‹¤íŒ¨: {e}")
        sys.exit(1)

    # --- 3. RAG í”„ë¡¬í”„íŠ¸ ì •ì˜ (LLMì´ ë‹µë³€ì„ ë” ì˜ ìƒì„±í•˜ë„ë¡ ìœ ë„) ---
    prompt = ChatPromptTemplate.from_template("""
    ë‹¹ì‹ ì€ ì‚¬ìš©ìì—ê²Œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ìœ ëŠ¥í•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
    ì£¼ì–´ì§„ ë¬¸ë§¥(context)ì„ ì£¼ì˜ ê¹Šê²Œ ì½ê³ , ì§ˆë¬¸ì— ê°€ì¥ ì í•©í•œ ì •ë³´ë¥¼ ì°¾ì•„ ìš”ì•½í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
    **ë°˜ë“œì‹œ ì£¼ì–´ì§„ ë¬¸ë§¥ì—ì„œ ì°¾ì€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•˜ë©°, ë‹¹ì‹ ì˜ ì‚¬ì „ ì§€ì‹ì„ ì¶”ê°€í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.**
    ë§Œì•½ ì£¼ì–´ì§„ ë¬¸ë§¥ì— ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ì •ë³´ê°€ ì „í˜€ ì—†ë‹¤ë©´,
    **"ì œê³µëœ ì •ë³´ë§Œìœ¼ë¡œëŠ” ë‹µë³€í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤."** ë¼ê³  ëª…í™•í•˜ê²Œ ë§í•˜ì„¸ìš”.
    ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì •ë³´ê°€ ë¬¸ë§¥ì— ìˆë‹¤ë©´ ê·¸ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.
    **ëª¨ë“  ë‹µë³€ì€ ê¼­ í•œêµ­ì–´(korean) ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.**

    [ì»¨í…ìŠ¤íŠ¸]
    {context}
    
    [ì§ˆë¬¸]
    {input}
    
    [ë‹µë³€]
    """)

    # --- 4. RAG ì²´ì¸ êµ¬ì„± ---
    document_chain = create_stuff_documents_chain(llm, prompt)
    rag_chain = create_retrieval_chain(compression_retriever, document_chain) # ì••ì¶• ë¦¬íŠ¸ë¦¬ë²„ ì‚¬ìš©

    print("\n--- RAG ì²´ì¸ êµ¬ì¶• ì™„ë£Œ. ì´ì œ ì§ˆë¬¸í•˜ì„¸ìš”. ---")
    print("ğŸ’¡ ì´ ì‹œìŠ¤í…œì€ ë¯¸ë¦¬ ì¸ë±ì‹±ëœ ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.")

    # --- 5. ì§ˆì˜ ì‘ë‹µ ë£¨í”„ ---
    while True:
        question = input("\nì§ˆë¬¸í•˜ì„¸ìš” (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥): ")
        if question.lower() == 'exit':
            break
        
        try:
            print(f"\n[Thinking...] ì§ˆë¬¸: {question}")
            response = rag_chain.invoke({"input": question})
            
            print("\n--- ì§ˆì˜ ì‘ë‹µ ê²°ê³¼ ---")
            print(f"ë‹µë³€: {response['answer']}")
            
            # ë””ë²„ê¹…ì„ ìœ„í•´ ê²€ìƒ‰ëœ ë¬¸ì„œë„ í•¨ê»˜ ì¶œë ¥í•©ë‹ˆë‹¤.
            print("\n--- ê²€ìƒ‰ëœ ë¬¸ì„œ (Context) ë¯¸ë¦¬ë³´ê¸° (LLMì— ì „ë‹¬ëœ ìµœì¢… ì»¨í…ìŠ¤íŠ¸) ---")
            if 'context' in response and response['context']:
                for i, doc in enumerate(response['context']):
                    print(f"  --- ê²€ìƒ‰ ë¬¸ì„œ {i+1} ---")
                    print(f"    ì œëª©: {doc.metadata.get('title', 'N/A')}")
                    print(f"    ì¶œì²˜: {doc.metadata.get('source', 'N/A')}")
                    print(f"    ë‚´ìš©:\n{doc.page_content}\n") 
            else:
                print("  ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            print("----------------------\n")

        except Exception as e:
            print(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            print("Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€, ëª¨ë¸ì´ ì˜¬ë°”ë¥´ê²Œ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()